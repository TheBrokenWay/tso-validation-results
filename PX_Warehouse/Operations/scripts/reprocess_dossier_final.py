#!/usr/bin/env python3
"""
Reprocess Dossier_Final through the full pipeline: grade by content, sort by tier,
relabel filenames to match grade, and guarantee no files are lost.

- Scans CommercialAssets/Dossier_Final recursively (flat + any subdirs).
- Grades each dossier using OLYMPUS logic (toxicity, PTA, responder rate).
- Moves to Gold / Silver / Learning_Material with relabeled names (DOSSIER_<GRADE>_<id>.json).
- Handles destination collisions (dedup suffix) so no file overwrites.
- Writes Executive_Summary per dossier.
- Writes a manifest and verifies total count before/after.
"""
from __future__ import annotations

import json
import os
import shutil
import sys
from datetime import datetime, timezone
from pathlib import Path

# Repo root: this script lives at PX_Warehouse/Operations/scripts/
_SCRIPT_DIR = Path(__file__).resolve().parent
_REPO_ROOT = _SCRIPT_DIR.parents[1]
_WAREHOUSE_ROOT = _REPO_ROOT / "PX_Warehouse" / "CommercialAssets"

FOLDERS = {
    "INBOX": _WAREHOUSE_ROOT / "Dossier_Final",
    "GOLD": _WAREHOUSE_ROOT / "Gold",
    "SILVER": _WAREHOUSE_ROOT / "Silver",
    "LEARNING": _WAREHOUSE_ROOT / "Learning_Material",
    "SUMMARY": _WAREHOUSE_ROOT / "Executive_Summary",
}


def ensure_architecture() -> None:
    for key, path in FOLDERS.items():
        path.mkdir(parents=True, exist_ok=True)
    print("[REPROCESS] Architecture ensured: Gold, Silver, Learning_Material, Executive_Summary.")


def grade_dossier(data: dict) -> tuple[str, Path]:
    """Return (grade, target_folder_path). Grade is one of GOLD, SILVER, LEARNING, REJECTED_TRASH."""
    efficacy = data.get("virtual_efficacy") or {}
    responder_rate = (efficacy.get("responder_rate") or {}).get("response_ratio", 0.0)
    pta = (efficacy.get("pk_pta") or {}).get("auc_mg_h_per_L") or {}
    pta_val = pta.get("pta", 0.0)

    admet = data.get("admet") or {}
    tox = (admet.get("toxicity") or {}).get("toxicity_index", 1.0)

    if tox >= 0.0210:
        return "REJECTED_TRASH", FOLDERS["LEARNING"]
    if pta_val >= 30.0 and responder_rate >= 0.3 and tox < 0.0200:
        return "GOLD", FOLDERS["GOLD"]
    if pta_val >= 20.0 and responder_rate >= 0.2 and tox < 0.0210:
        return "SILVER", FOLDERS["SILVER"]
    return "LEARNING", FOLDERS["LEARNING"]


def relabel_filename(old_name: str, grade: str) -> str:
    """Produce DOSSIER_<GRADE>_<rest>.json from DOSSIER_*_<rest>.json."""
    if not old_name.endswith(".json"):
        return f"DOSSIER_{grade}_{old_name}"
    base = old_name[:-5]  # strip .json
    parts = base.split("_")
    if len(parts) >= 3 and parts[0] == "DOSSIER":
        rest = "_".join(parts[2:])
        return f"DOSSIER_{grade}_{rest}.json"
    return f"DOSSIER_{grade}_{base}.json"


def generate_summary(data: dict, filename: str, grade: str) -> None:
    """Write Executive_Summary markdown (same contract as consolidate_warehouse)."""
    name = (data.get("metadata") or {}).get("name", "Unknown_Compound")
    smiles = (data.get("metadata") or {}).get("smiles", "N/A")
    efficacy = data.get("virtual_efficacy") or {}
    rr = efficacy.get("responder_rate") or {}
    pta = (efficacy.get("pk_pta") or {}).get("auc_mg_h_per_L") or {}
    do = data.get("dose_optimization") or {}

    summary_text = f"""# EXECUTIVE SUMMARY: {name}
**Grade**: {grade}
**Date**: {datetime.now().strftime('%Y-%m-%d')}

## Commercial Profile
* **Compound**: {name}
* **SMILES**: `{smiles}`
* **Classification**: {grade} Tier Asset

## Virtual Clinical Data
* **Responder Rate**: {rr.get('response_ratio', 'N/A')}
* **Target Attainment (PTA)**: {pta.get('pta', 'N/A')}%
* **Safety Margin**: {do.get('safety_margin', 'N/A')}x

---
*Generated by Dossier_Final reprocess pipeline*
"""
    safe_name = "".join(c if c.isalnum() or c in "._- " else "_" for c in name)
    summary_path = FOLDERS["SUMMARY"] / f"{safe_name}_Summary.md"
    idx = 0
    while summary_path.exists():
        idx += 1
        summary_path = FOLDERS["SUMMARY"] / f"{safe_name}_Summary_{idx}.md"
    summary_path.write_text(summary_text, encoding="utf-8")


def collect_all_dossier_jsons(inbox: Path) -> list[Path]:
    """Recursive: all .json files under inbox (flat and in subdirs)."""
    out: list[Path] = []
    for p in inbox.rglob("*.json"):
        if p.is_file():
            out.append(p)
    return sorted(out)


def unique_dest(target_dir: Path, base_name: str) -> Path:
    """Return a path in target_dir that does not exist; add _dedup_N if needed."""
    dest = target_dir / base_name
    if not dest.exists():
        return dest
    stem = base_name[:-5] if base_name.endswith(".json") else base_name
    ext = ".json" if base_name.endswith(".json") else ""
    n = 1
    while True:
        dest = target_dir / f"{stem}_dedup_{n}{ext}"
        if not dest.exists():
            return dest
        n += 1


def run_reprocess(dry_run: bool = False) -> dict:
    """
    Scan Dossier_Final, grade each file, move with relabel, write summaries and manifest.
    If dry_run=True, only report what would be done; no moves or writes.
    Returns manifest dict for audit.
    """
    ensure_architecture()
    inbox = FOLDERS["INBOX"]
    all_files = collect_all_dossier_jsons(inbox)
    total = len(all_files)
    print(f"[REPROCESS] Found {total} dossier(s) under {inbox}")

    manifest = {
        "run_ts": datetime.now(timezone.utc).isoformat(),
        "source_folder": str(inbox),
        "total_input": total,
        "by_grade": {"GOLD": 0, "SILVER": 0, "LEARNING": 0, "REJECTED_TRASH": 0, "CORRUPT": 0},
        "moves": [],
    }

    for i, src in enumerate(all_files):
        src_str = str(src)
        name = src.name
        try:
            with open(src, "r", encoding="utf-8") as f:
                data = json.load(f)
        except Exception as e:
            print(f"  [ERROR] Corrupt: {name} -> {e}")
            manifest["by_grade"]["CORRUPT"] += 1
            if not dry_run:
                dest = unique_dest(FOLDERS["LEARNING"], f"CORRUPT_{name}")
                shutil.move(src_str, str(dest))
                manifest["moves"].append({"src": src_str, "dest": str(dest), "grade": "CORRUPT"})
            continue

        grade, target_dir = grade_dossier(data)
        manifest["by_grade"][grade] = manifest["by_grade"].get(grade, 0) + 1

        new_name = relabel_filename(name, grade)
        dest_path = unique_dest(target_dir, new_name)

        if dry_run:
            if (i + 1) % 1000 == 0 or (i + 1) == total:
                print(f"  [DRY] {i + 1}/{total} ...")
            continue

        shutil.move(src_str, str(dest_path))
        manifest["moves"].append({"src": src_str, "dest": str(dest_path), "grade": grade})
        generate_summary(data, name, grade)

        if (i + 1) % 500 == 0 or (i + 1) == total:
            print(f"  [SORT] {i + 1}/{total} -> {grade}: {dest_path.name}")

    # Verification
    moved_count = len(manifest["moves"])
    grade_sum = sum(manifest["by_grade"].values())
    if not dry_run and total != grade_sum:
        print(f"[REPROCESS] WARNING: total input {total} != by_grade sum {grade_sum}")
    if not dry_run:
        print(f"[REPROCESS] Moved {moved_count} files. By grade: {manifest['by_grade']}")

    return manifest


def main() -> None:
    import argparse
    p = argparse.ArgumentParser(description="Reprocess Dossier_Final through pipeline; sort and relabel.")
    p.add_argument("--dry-run", action="store_true", help="Only report; do not move or write.")
    p.add_argument("--manifest", type=str, default="", help="Write manifest JSON to this path (e.g. PX_LOGS/...).")
    args = p.parse_args()

    manifest = run_reprocess(dry_run=args.dry_run)

    if args.manifest and not args.dry_run:
        out_path = Path(args.manifest)
        if not out_path.is_absolute():
            out_path = _REPO_ROOT / out_path
        out_path.parent.mkdir(parents=True, exist_ok=True)
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(manifest, f, indent=2)
        print(f"[REPROCESS] Manifest written: {out_path}")


if __name__ == "__main__":
    main()
